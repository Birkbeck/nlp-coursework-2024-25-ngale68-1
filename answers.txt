Question 1(d):
The Flesch-Kincaid (FK) score can be unreliable in two key scenarios:

1. Non-standard grammar or literary style:
FK assumes standard sentence structure and punctuation. Texts with irregular grammar, such as
stream-of-consciousness writing (e.g., James Joyce), or those with long, complex sentences 
broken by semicolons or em dashes, can confuse sentence tokenizers and distort average sentence 
length, leading to misleading scores.

2. Vocabulary and conceptual complexity:
FK is based only on surface-level metrics — word length (syllables) and sentence length — and 
does not account for semantic difficulty. A text can have short, simple words and sentences but 
convey complex, abstract, or domain-specific concepts (e.g., legal or philosophical texts), 
which are cognitively demanding despite scoring as “easy.”

Additionally, FK performs poorly on poetry, dialogue-heavy texts, or any content where 
readability depends more on cultural context or background knowledge than linguistic structure.


Question 2(f):
My custom tokenizer uses spaCy to lemmatize each token, convert it to lowercase, and exclude 
stopwords and non-alphabetic tokens. Lemmatization generalizes across inflected forms, 
improving consistency and reducing feature sparsity. I also configured TfidfVectorizer to extract 
unigrams, bigrams, and trigrams (ngram_range=(1,3)), and limited features to terms appearing in 
at least 3 documents and no more than 80% of documents. This helped eliminate noise and overly 
common terms while preserving meaningful phrases like “public spending” or “Mr Speaker said”.

Using this setup, the Linear SVM classifier achieved a macro-average F1 score of 0.78 and an 
accuracy of 84%, outperforming Random Forest (macro F1 = 0.67). The model performed strongly 
on the Conservative class (F1 = 0.89) and Labour (F1 = 0.75), while the Scottish National Party 
showed lower recall (0.62), likely due to its smaller class size. Overall, this approach 
achieved a solid balance between performance and efficiency, respecting the 3000-feature limit 
while capturing both token-level and phrase-level context for classification.

I also tested more permissive thresholds (min_df=2, max_df=0.9), but this yielded no meaningful 
improvement, confirming that the original configuration provides an optimal balance. And 
(min_df=4, max_df=0.7) yielded a worse performance with no significant efficiency.